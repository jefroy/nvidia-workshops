{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5870529-22a4-4dcb-a507-0f14b7b2185f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 28 10:42:44 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA TITAN RTX               Off |   00000000:07:00.0 Off |                  N/A |\n",
      "| 41%   27C    P8              1W /  280W |       8MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1787      G   /usr/bin/gnome-shell                            3MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc95bc4-6a3e-4ca0-bcc7-5f029883e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain import hub\n",
    "from langchain.chains import RetrievalQA\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf17a8c5-18a1-4c6f-8a11-f0628d14b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the pickle file\n",
    "with open(\"Downloads/shadowrun5e_database.pkl\", 'rb') as file:\n",
    "    documents = pk.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82e08e9-3594-43f4-9ff0-974cd8bd7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b357cb0d-9793-4a8c-bf22-960fddacd89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06efcfcb-2f22-42cd-b00b-65df5c49fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34117dc5-8553-4c42-8a41-e8d5245d9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(all_splits, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "512d43ab-5c83-415a-b050-cda7a1c5ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"gemma3:27b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d90bc83-9bfd-4593-bb5f-02545f393391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mo/.local/lib/python3.12/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55242e5c-cbc8-435b-8129-66123cb7d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    retriever=db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc544b9e-90a3-4bbd-9f75-1723c79725a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 28 10:44:44 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA TITAN RTX               Off |   00000000:07:00.0 Off |                  N/A |\n",
      "| 41%   35C    P8              1W /  280W |     530MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1787      G   /usr/bin/gnome-shell                            3MiB |\n",
      "|    0   N/A  N/A      3597      C   /home/mo/anaconda3/envs/rag/bin/python        522MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d59f103-5c43-41d8-b667-ae72110b87ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Q:  What is Shadowrun?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Shadowrun is a cyberpunk/urban fantasy setting where players become “shadowrunners” – deniable assets who take on illegal or dangerous jobs. It’s set in a dystopian future—the Sixth World—with elements of magic, technology, and corporate conflict. Players can be street samurai, mages, deckers, and more, completing jobs for pay in a world filled with danger and intrigue.\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc3e3b-a1a4-427e-9f84-d9d541ca46c3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce024202-20c6-4b65-9d13-1172de168f7e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd9e29-8d26-4bda-9822-668d3d60e2cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e22d8-df5a-45a2-a8b0-cb84b09f4feb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b93da-032f-4bcf-ab22-c7bf4f4e8a26",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88665e-dd06-4109-89b1-8e4f30bd0d92",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f318ec-a2f9-4f42-8fa2-0f1c898edbbe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d307a2c8-36c0-4b39-9965-a9bef6a16934",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5876b7b4-cce4-4ed8-bbc2-d9ef807b2af0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eb00b0-021c-44b9-b303-c6f662e60623",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac4e17-264b-4aa9-b6fa-b97084cce2ec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaeef73-fdf5-4b11-bafe-5ffb95f15697",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9aba2-b35d-4675-b807-171308438338",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fffabd-c074-4e1f-bbb5-ee48efe9b2e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caac0f7c-3415-4096-985f-5d0d9f0a1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input(\"Q: \")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"A:\", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
